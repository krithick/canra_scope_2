take a look at the question bot class and api flow

---

I'll examine the question bot class and API flow in your project. Let me start by exploring the project structure to understand the codebase.

---

Now let me examine the question bot class and related files to understand the API flow:

---

Let me also check the database and factory files to understand the complete API flow:

---

Now let me check if there's a main API file to see the complete flow:

---

Let me check the dynamic.py file which might contain the API endpoints:

---

Now let me check the mongo.py file to understand the database operations:

---

Based on my analysis of the codebase, here's an overview of the **QuestionBot class and API flow**:

## QuestionBot Class Overview

The `QuestionBot` is a specialized bot that inherits from `BaseLLMBot` and is designed for **API-only usage** (no chat integration). It provides interactive question training sessions with the following key features:

### Core Functionality
- **Dynamic Question Paraphrasing**: Uses LLM to rephrase questions based on difficulty (easy/hard)
- **Session Management**: Tracks user progress through question sets
- **Answer Validation**: Checks correctness and provides feedback
- **Explanation Validation**: Uses AI to validate user explanations for correct answers
- **Competency Analysis**: Tracks performance across different skill areas

### Key Methods
1. **`start_new_session()`** - Creates new training session with paraphrased questions
2. **`submit_answer()`** - Processes answer submissions and provides feedback
3. **`submit_explanation()`** - Validates explanations for correct answers
4. **`get_session_results()`** - Returns comprehensive session analytics

## API Flow Architecture

### 1. **Session Lifecycle**
```
POST /api/question-sessions/start
  ↓
POST /api/question-sessions/{id}/answer
  ↓ (if correct)
POST /api/question-sessions/{id}/explain
  ↓ (repeat until complete)
GET /api/question-sessions/{id}/results
```

### 2. **Data Flow**
1. **Scenario Setup**: Questions loaded from MongoDB via `QuestionScenarioDoc`
2. **Bot Factory**: `DynamicBotFactory` creates and manages QuestionBot instances
3. **Session Creation**: New session with paraphrased questions generated concurrently
4. **Answer Processing**: Validates answers, tracks attempts, provides AI feedback
5. **Explanation Validation**: Uses LLM to assess user understanding
6. **Results Analytics**: Competency scoring and performance insights

### 3. **Key Components**

**Models**:
- `QuestionSession` - Main session tracking
- `QuestionAttemptRecord` - Detailed attempt logging
- `ParaphrasedQuestionCache` - Cached question variations

**Database Operations** (MongoDB):
- Question scenarios storage
- Session persistence
- Paraphrase caching
- Analytics data

**LLM Integration**:
- Google Gemini 2.0 Flash for question paraphrasing
- AI-powered explanation validation
- Dynamic feedback generation

### 4. **API Endpoints Structure**

**Core Session APIs**:
- Start session, submit answers, submit explanations, get results

**Management APIs**:
- Scenario creation, paraphrase generation, analytics

**Bot Management**:
- Dynamic bot creation and refresh

The system is designed for **scalable, API-first question training** with sophisticated AI-powered assessment and feedback mechanisms.

---

the thing with this is that i need to introduce two entiees now on eis that for answer api the fronteedn sends the option instead of option the frotend will give whateber the user spoke as a text so now we introduce a new llm call to verify if the anser is one of four and continue the flow if not i.e if he gives a irrevent text or answer that should be also handled and there is a time limit to answer the questions in frontend if the question is not answerd there should a flow for that too just showing the correct answer and moviung on ot the next question now we are requireng a ansewer to move to a new question right

---

I'll help you modify the QuestionBot to handle speech-to-text answers and timeout scenarios. Here are the minimal changes needed:

---

Adding speech answer processing and timeout handling to the submit_answer method

---

Adding helper methods for speech processing and timeout handling

---

Adding helper methods for speech processing and timeout handling

---

Updating the API endpoint to handle speech input and timeout

---

Updating the API endpoint to handle speech input and timeout

---

The key changes implemented:

## Modified `submit_answer()` method:
- **Parameter change**: `selected_option` → `user_input` (accepts speech text)
- **New parameters**: `is_timeout` flag for timeout handling
- **Speech processing**: Uses LLM to extract A/B/C/D from speech text
- **Invalid input handling**: Returns retry message for unclear speech

## New helper methods:
- **`_extract_option_from_speech()`**: Uses LLM to parse speech and extract option
- **`_handle_timeout()`**: Processes timeout scenarios, shows correct answer, moves to next question

## Updated API endpoints:
- **Modified `/answer`**: Now accepts `user_input` (speech) and `is_timeout` flag
- **New `/timeout`**: Dedicated endpoint for timeout handling

## Flow changes:
1. **Speech input** → LLM extracts option → Continue normal flow
2. **Invalid speech** → Return retry message (no question progression)
3. **Timeout** → Show correct answer → Auto-move to next question
4. **No answer required** → Questions can now auto-advance on timeout

The system now handles speech-to-text answers and timeout scenarios while maintaining the existing question progression logic.

---

can you update the front end code too waityou are not parsing the audio are you ???

---

You're right - I'm not parsing audio. The frontend needs to handle speech-to-text conversion first, then send the text to the backend. Here's the minimal frontend code:

---

Creating minimal frontend with speech-to-text and timeout handling

---

Creating frontend directory

---

Creating minimal frontend with speech-to-text and timeout handling

---

The frontend handles:

## Speech Recognition
- **Browser API**: Uses `webkitSpeechRecognition` for speech-to-text
- **Real-time conversion**: Converts speech to text, then sends to backend
- **Error handling**: Fallback for failed recognition

## Timer & Timeout
- **30-second countdown**: Visual timer for each question
- **Auto-timeout**: Calls backend with `is_timeout: true` when time expires
- **Timer controls**: Stops on answer submission or timeout

## Flow Management
- **Speech → Text → Backend**: Frontend does speech-to-text, backend processes text
- **Retry logic**: Handles invalid answers with retry option
- **Auto-progression**: Moves to next question or explanation based on response

## Key Features
- **No audio parsing in backend**: Frontend converts speech to text first
- **Timeout handling**: Auto-submits when timer expires
- **Explanation recording**: Separate speech input for explanations
- **Session management**: Tracks progress and shows final results

The system now properly separates concerns: frontend handles audio → text conversion, backend processes text and manages question logic.

---

no i have a react code here right just alter it based on the new input

---

Adding speech recognition and timeout handling to the React component

---

The React component now includes:

## Speech Recognition
- **Browser API integration**: Uses `webkitSpeechRecognition`
- **Real-time transcription**: Shows "You said: ..." feedback
- **Dual input**: Speech recording + manual text input

## Timer & Timeout
- **Visual countdown**: 30-second timer with color coding (red when ≤10s)
- **Auto-timeout**: Calls backend with `is_timeout: true` when timer expires
- **Timer management**: Starts/stops appropriately during question flow

## Enhanced UI
- **Recording buttons**: Start/Stop recording with visual feedback
- **Speech display**: Shows transcribed text before submission
- **Fallback input**: Manual text input as backup option
- **Retry handling**: Allows retry for invalid speech input

## Key Changes
- **`submitAnswer()`**: Now accepts speech input parameter
- **`handleAnswerResponse()`**: Processes retry logic for invalid speech
- **Timer integration**: Starts timer when questions load, stops on submission/timeout
- **Speech state management**: Tracks recording status and transcribed text

The component maintains all existing functionality while adding speech input and timeout capabilities.

---

update the flow and the documentation tooo

---

Updating API documentation with new speech input and timeout flow

---

Updating API documentation with new speech input and timeout flow

---

Creating comprehensive flow documentation for the updated system

---


The documentation has been updated with:

## API Documentation Changes
- **New request parameters**: `user_input`, `is_timeout` instead of `selected_option`
- **New response types**: Invalid speech retry, timeout handling
- **Enhanced examples**: Speech input and timeout scenarios
- **Updated flow diagrams**: Speech processing and timeout paths

## New Flow Documentation
- **Complete flow diagram**: Visual representation of speech + timeout handling
- **API migration guide**: How parameters changed
- **Frontend integration**: Speech recognition and timer setup
- **Backend processing**: LLM option extraction and timeout handling

## Key Updates
1. **Speech-first approach**: Users speak naturally, LLM extracts options
2. **Non-blocking progression**: Questions always advance (timeout/incorrect)
3. **Retry mechanism**: Only for invalid speech input
4. **Enhanced UX**: Visual timers, dual input methods, clear feedback

The system now supports natural speech interaction while maintaining robust timeout handling and automatic question progression.